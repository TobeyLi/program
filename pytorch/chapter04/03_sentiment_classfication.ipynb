{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 新闻情感分类：RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import tarfile\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext.vocab as Vocab\n",
    "import torch.utils.data as Data\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import  torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "# 设置GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DATA_ROOT=\"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname=os.path.join(DATA_ROOT,\"aclImdb_v1.tar.gz\")\n",
    "if not os.path.exists(os.path.join(DATA_ROOT,'aclImdb')):\n",
    "    print(\"compress from tarfile.\")\n",
    "    with tarfile.open(fname,'r') as f:\n",
    "        f.extractall(DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:04<00:00, 2961.68it/s]\n",
      "100%|██████████| 12500/12500 [00:04<00:00, 2847.36it/s]\n",
      "100%|██████████| 12500/12500 [00:04<00:00, 3047.81it/s]\n",
      "100%|██████████| 12500/12500 [00:04<00:00, 3020.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# 读取训练数据\n",
    "def read_imdb(folder=\"train\",data_root=\"../data/aclImdb\"):\n",
    "    data=[]\n",
    "    for label in [\"pos\",\"neg\"]:\n",
    "        folder_name=os.path.join(data_root,folder,label)\n",
    "        for target_file in tqdm(os.listdir(folder_name)):\n",
    "            with open(os.path.join(folder_name, target_file), 'rb') as f:\n",
    "                review = f.read().decode('utf-8').replace('\\n', '').lower()\n",
    "                data.append([review, 1 if label == 'pos' else 0])\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "train_data, test_data = read_imdb('train'), read_imdb('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i\\'ll keep this short; thanks to greg for helping me to put this succinctly: captivity is about a guy who drugs a girl\\'s drink, imprisons and tortures her, then poses as a captive to have sex with her. that is the single twist and punchline of the film. it\\'s torture as slow motion date rape. and, it\\'s not even a good movie. it\\'s not so bad it\\'s good; it\\'s just bad.<br /><br />it should also be mentioned that among critics, there is a \"spoiler code\" that they dare not break, even though some were tempted to on this one because it is so vile. why no one had the cojones to step up and say, \"this is garbage, and this is why,\" is beyond me.<br /><br />don\\'t give your money to these poop-peddlers.',\n",
       " 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据格式\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in vocab: 46152\n"
     ]
    }
   ],
   "source": [
    "# 获取分词结果\n",
    "def get_tokenized_imdb(data):\n",
    "    \"\"\"\n",
    "    data: list of [string, label]\n",
    "    \"\"\"\n",
    "    def tokenizer(text):\n",
    "        return [token.lower() for token in text.split(\" \")]\n",
    "    return [tokenizer(review) for review, _ in data]\n",
    "\n",
    "# 根据分词的结果创建词典\n",
    "def get_vocab_imdb(data):\n",
    "    tokenized_data=get_tokenized_imdb(data)\n",
    "    counter=collections.Counter([tk for st in tokenized_data for tk in st])\n",
    "    return Vocab.Vocab(counter, min_freq=5)\n",
    "\n",
    "vocab = get_vocab_imdb(train_data)\n",
    "print('# words in vocab:', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过截断或者补0来将每条评论长度固定成500。\n",
    "def precess_imdb(data,vocab,max_len=500):\n",
    "    def padding(x):\n",
    "        return x[:max_len] if len(x)>max_len else x+[0]*(max_len-len(x))\n",
    "    tokenized_data = get_tokenized_imdb(data)\n",
    "    features = torch.tensor([padding([vocab.stoi[word] for word in words]) for words in tokenized_data])\n",
    "    labels = torch.tensor([score for _, score in data])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据迭代器\n",
    "batch_size=64\n",
    "train_set=Data.TensorDataset(*precess_imdb(train_data,vocab))\n",
    "test_set=Data.TensorDataset(*precess_imdb(test_data,vocab))\n",
    "\n",
    "# 创建迭代器\n",
    "train_iter = Data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "test_iter = Data.DataLoader(test_set, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X torch.Size([64, 500]) y torch.Size([64])\n",
      "tensor([  10,    7,  111, 1430,  649,  289,   34,    2,    0,   17])\n",
      "#batches: 391\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_iter:\n",
    "    print('X', X.shape, 'y', y.shape)\n",
    "    print(X[0][:10])\n",
    "    break\n",
    "print('#batches:', len(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义RNN神经网络\n",
    "class BiRNN(nn.Module):\n",
    "    def __init__(self,hidden_size,embedding_size,vocab,num_layers):\n",
    "        super(BiRNN,self).__init__()\n",
    "        self.embedding=nn.Embedding(len(vocab),embedding_size)\n",
    "        self.encoder=nn.LSTM(input_size=embedding_size,hidden_size=hidden_size,\n",
    "                             num_layers=num_layers,batch_first=True,bidirectional=True)\n",
    "        self.fc=nn.Linear(in_features=4*hidden_size,out_features=2)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        \"\"\"\n",
    "        inputs: (batch_size,features)\n",
    "        \"\"\"\n",
    "        # embedd.shape=(batch_size,feature_size,embedding_size)\n",
    "        embedd=self.embedding(inputs)\n",
    "        # output.shape:(batch_size,feature_size,hidden_size*num_layer)\n",
    "        outputs,_=self.encoder(embedd)\n",
    "        # 连结初始时间步和最终时间步的隐藏状态作为全连接层输入\n",
    "        encoding = torch.cat((outputs[:,0,:], outputs[:,-1,:]), -1)\n",
    "        outs = self.fc(encoding)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size, num_hiddens, num_layers = 100, 100, 2\n",
    "net = BiRNN(num_hiddens,embed_size,vocab,num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 导入预训练模型\n",
    "glove_vocab = Vocab.GloVe(name='6B', dim=100, cache=os.path.join(\"../data\", \"pretrain_models\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21202 oov words.\n"
     ]
    }
   ],
   "source": [
    "# 导入词向量\n",
    "def load_pretrained_embedding(words,pretrained_vocab):\n",
    "    embed=torch.zeros(len(words), pretrained_vocab.vectors[0].shape[0])\n",
    "    oov_count = 0\n",
    "    for i,word in enumerate(words):\n",
    "        try:\n",
    "            index=pretrained_vocab.stoi[word]\n",
    "            embed[i, :] = pretrained_vocab.vectors[index]\n",
    "        except KeyError:\n",
    "            oov_count += 1\n",
    "    if oov_count > 0:\n",
    "        print(\"There are %d oov words.\" % oov_count)\n",
    "    return embed\n",
    "# 加载预训练词向量\n",
    "net.embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "lr, num_epochs = 0.01, 5\n",
    "optimizer=torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    net.eval() # 评估模式, 这会关闭dropout\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "    net.train() # 改回训练模式\n",
    "    return acc_sum / n\n",
    "\n",
    "def train(train_iter,test_iter,net,criterion,optimizer,device,num_epochs):\n",
    "    net=net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    batch_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X,y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y=y.view(-1)\n",
    "#             print(\"X.shape=\",X.shape)\n",
    "#             print(\"y.shape=\",y.shape)\n",
    "            y_hat=net(X)\n",
    "#             print(\"y_hat.shape=\",y_hat.shape)\n",
    "            loss=criterion(y_hat,y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            # 梯度迭代\n",
    "            loss.backward()\n",
    "            #  参数更新\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_l_sum += loss.cpu().item()\n",
    "            train_acc_sum+=(y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        evaluate_accuracy(test_iter,net,device)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train(train_iter, test_iter, net, criterion, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(net,vocab,sentence):\n",
    "    \"\"\"\n",
    "    sentence:list-like\n",
    "    \"\"\"\n",
    "    device = list(net.parameters())[0].device\n",
    "    sentence = torch.tensor([vocab.stoi[word] for word in sentence], device=device)\n",
    "    label = torch.argmax(net(sentence.view((1, -1))), dim=1)\n",
    "    return 'positive' if label.item() == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, ['this', 'movie', 'is', 'so', 'great'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络textCNN\n",
    "主要是在信息抽取的方式，通过引入卷积核，来获取特征之间的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  5.,  8., 11., 14., 17.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义一维互相关运算\n",
    "def corr1d(X, K):\n",
    "    \"\"\"\n",
    "    X:输入的一维list\n",
    "    K：卷积核\n",
    "    @returen: 返回一维卷积运算的结果\n",
    "    \"\"\"\n",
    "    w=K.shape[0]\n",
    "    Y = torch.zeros((X.shape[0] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        Y[i]=(X[i: i + w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "X, K = torch.tensor([0, 1, 2, 3, 4, 5, 6]), torch.tensor([1, 2])\n",
    "corr1d(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  8., 14., 20., 26., 32.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 多输入通道的一维互相关运算也与多输入通道的二维互相关运算类似：在每个通道上，将核与相应的输入做一维互相关运算，\n",
    "# 并将通道之间的结果相加得到输出结果。\n",
    "def corr1d_multi_in(X,K):\n",
    "    \"\"\"\n",
    "    多输入通道的一维互相关运算\n",
    "    \"\"\"\n",
    "    return torch.stack([corr1d(x, k) for x, k in zip(X, K)]).sum(dim=0)\n",
    "X = torch.tensor([[0, 1, 2, 3, 4, 5, 6],\n",
    "              [1, 2, 3, 4, 5, 6, 7],\n",
    "              [2, 3, 4, 5, 6, 7, 8]])\n",
    "K = torch.tensor([[1, 2], [3, 4], [-1, -3]])\n",
    "corr1d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时序最大池化层\n",
    "class GlobalMaxPool1d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalMaxPool1d, self).__init__()\n",
    "    def forward(self, x):\n",
    "         # x shape: (batch_size, channel, seq_len)\n",
    "         # return shape: (batch_size, channel, 1)\n",
    "        return F.max_pool1d(x, kernel_size=x.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self,vocab,embedding_size,kernel_sizes,num_channels):\n",
    "        super(TextCNN,self).__init__()\n",
    "        self.embedding=nn.Embedding(len(vocab),embedding_size)\n",
    "        # 不参与训练的嵌入层\n",
    "        self.constant_embedding=nn.Embedding(len(vocab),embedding_size)\n",
    "        self.dropout=nn.Dropout(0.5)\n",
    "        self.decoder = nn.Linear(sum(num_channels), 2)\n",
    "        \n",
    "        # 时序最大池化层没有权重，所以可以共用一个实例\n",
    "        self.pool = GlobalMaxPool1d()\n",
    "        self.convs = nn.ModuleList()  # 创建多个一维卷积层\n",
    "        for c, k in zip(num_channels, kernel_sizes):\n",
    "            self.convs.append(nn.Conv1d(in_channels = 2*embed_size, out_channels = c, kernel_size = k))\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        # (batch, seq_len, 2*embed_size)\n",
    "        embeddings = torch.cat((self.embedding(inputs), self.constant_embedding(inputs)), dim=2) \n",
    "        # 根据Conv1D要求的输入格式，将词向量维，即一维卷积层的通道维(即词向量那一维)，变换到前一维\n",
    "        embeddings = embeddings.permute(0, 2, 1)\n",
    "        # 对于每个一维卷积层，在时序最大池化后会得到一个形状为(批量大小, 通道大小, 1)的Tensor。使用flatten函数去掉最后一维，然后在通道维上连结\n",
    "        encoding = torch.cat([self.pool(F.relu(conv(embeddings))).squeeze(-1) for conv in self.convs], dim=1)\n",
    "        # 应用丢弃法后使用全连接层得到输出\n",
    "        outputs = self.decoder(self.dropout(encoding))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size, kernel_sizes, nums_channels = 100, [3, 4, 5], [100, 100, 100]\n",
    "net = TextCNN(vocab, embed_size, kernel_sizes, nums_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21202 oov words.\n",
      "There are 21202 oov words.\n"
     ]
    }
   ],
   "source": [
    "# 导入预训练词向量\n",
    "glove_vocab = Vocab.GloVe(name='6B', dim=100,cache=os.path.join(\"../data\", \"pretrain_models\"))\n",
    "\n",
    "# 导入两种形式的embedding\n",
    "net.embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#train(train_iter, test_iter, net, criterion, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, ['this', 'movie', 'is', 'so', 'great'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
